apiVersion: v1
kind: Pod
metadata:
  name: cuda-ipc-producer-shared
  labels:
    app: cuda-ipc-producer-shared
spec:
  hostIPC: true
  hostPID: true
  nodeSelector:
    cloud.google.com/gke-accelerator: nvidia-tesla-a100
  containers:
  - name: producer
    image: nvidia/cuda:12.4.1-devel-ubuntu22.04
    command: ["/bin/bash", "-c"]
    args:
    - |
      cat > /tmp/producer.cu << 'EOF'
      #include <cuda_runtime.h>
      #include <stdio.h>
      #include <unistd.h>
      
      int main() {
          void* devPtr;
          cudaIpcMemHandle_t handle;
          
          printf("Producer: Allocating GPU memory...\n");
          cudaError_t err = cudaMalloc(&devPtr, 1024 * 1024); // 1MB
          if (err != cudaSuccess) {
              printf("ERROR allocating GPU memory: %s\n", cudaGetErrorString(err));
              return 1;
          }
          
          // Initialize memory with some data
          int* hostData = (int*)malloc(1024 * 1024);
          for (int i = 0; i < 256 * 1024; i++) {
              hostData[i] = i;
          }
          cudaMemcpy(devPtr, hostData, 1024 * 1024, cudaMemcpyHostToDevice);
          
          printf("Producer: Creating IPC handle...\n");
          err = cudaIpcGetMemHandle(&handle, devPtr);
          if (err != cudaSuccess) {
              printf("ERROR creating IPC handle: %s\n", cudaGetErrorString(err));
              return 1;
          }
          
          printf("Producer: Writing handle to shared volume...\n");
          FILE* f = fopen("/shared/cuda_ipc_handle.dat", "wb");
          if (!f) {
              printf("ERROR: Could not open handle file for writing\n");
              return 1;
          }
          fwrite(&handle, sizeof(handle), 1, f);
          fclose(f);
          
          // Also write the data size
          f = fopen("/shared/data_info.txt", "w");
          fprintf(f, "size=%d\ntype=int\ncount=%d\n", 1024*1024, 256*1024);
          fclose(f);
          
          printf("Producer: Handle written to /shared/cuda_ipc_handle.dat\n");
          printf("Producer: Keeping memory alive for 300 seconds...\n");
          
          sleep(300); // Keep the memory allocated for 5 minutes
          
          cudaFree(devPtr);
          free(hostData);
          printf("Producer: Cleanup complete\n");
          return 0;
      }
      EOF
      
      echo "Producer: Compiling CUDA code..."
      nvcc /tmp/producer.cu -o /tmp/producer
      echo "Producer: Starting execution..."
      /tmp/producer
    resources:
      limits:
        nvidia.com/gpu: 1
    securityContext:
      privileged: true
      capabilities:
        add: ["IPC_LOCK"]
    volumeMounts:
    - name: shared-volume
      mountPath: /shared
  
  volumes:
  - name: shared-volume
    hostPath:
      path: /tmp/cuda-ipc-shared
      type: DirectoryOrCreate
  
  restartPolicy: Never